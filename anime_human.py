# -*- coding: utf-8 -*-
"""ani_hu.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1OnlOvvqQsNCl6ll_pho5v4gLtoET1Vle
"""

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D,MaxPool2D ,Dense,Flatten,Dropout
import numpy as np
import matplotlib.pyplot as plt
import random
import os
from google.colab import drive
from tensorflow.keras.models import load_model

import numpy as np
import os
import cv2
from tqdm import tqdm


def load_images_from_folder(folder_path, max_images, label, target_size=(64, 64)):
    images = []
    labels = []
    count = 0
    for filename in tqdm(os.listdir(folder_path)):
        file_path = os.path.join(folder_path, filename)
        img = cv2.imread(file_path)
        if img is not None:
            # Resize ·∫£nh v·ªÅ k√≠ch th∆∞·ªõc 64x64
            img_resized = cv2.resize(img, target_size)
            images.append(img_resized)
            labels.append(label)
            count += 1
            if count >= max_images:
                break
    return np.array(images), np.array(labels)


anime_path = "/content/drive/MyDrive/anime_human/anime"
human_path = "/content/drive/MyDrive/anime_human/Human"

# Load d·ªØ li·ªáu v·ªõi s·ªë l∆∞·ª£ng y√™u c·∫ßu v√† resize v·ªÅ 64x64
x_anime, y_anime = load_images_from_folder(anime_path, max_images=1000, label=1)  # Anime = 1
x_human, y_human = load_images_from_folder(human_path, max_images=500, label=0)   # Human = 0


x_train_anime, x_test_anime = x_anime[:800], x_anime[800:1000]
y_train_anime, y_test_anime = y_anime[:800], y_anime[800:1000]


x_train_human, x_test_human = x_human[:400], x_human[400:500]
y_train_human, y_test_human = y_human[:400], y_human[400:500]


x_train = np.concatenate((x_train_anime, x_train_human), axis=0)
y_train = np.concatenate((y_train_anime, y_train_human), axis=0)

x_test = np.concatenate((x_test_anime, x_test_human), axis=0)
y_test = np.concatenate((y_test_anime, y_test_human), axis=0)


print("Train Data:", x_train.shape, "Train Labels:", y_train.shape)
print("Test Data:", x_test.shape, "Test Labels:", y_test.shape)

print(x_train[0])

x_train = x_train.astype('float32') / 255.0
x_test = x_test.astype('float32') / 255.0

print(x_train[0])

print(x_train.shape)
print(y_train.shape)
print(x_test.shape)
print(y_test.shape)

idx = np.random.randint(0, len(x_train))
plt.imshow(x_train[idx,:])
print(y_train[idx])

model = Sequential([
    Conv2D(32, (3, 3), activation='relu', input_shape=(64, 64, 3)),
    MaxPool2D((2, 2)),

    Conv2D(32, (3, 3), activation='relu'),
    MaxPool2D((2, 2)),

    Flatten(),
    Dense(64, activation='relu'),
    Dense(1, activation='sigmoid'),

])

model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])

model.fit(x_train, y_train, epochs=10, batch_size = 64 , validation_split=0.2)

drive.mount('/content/drive')

model.save('/content/drive/MyDrive/ani_hu.h5')

model = load_model('/content/drive/MyDrive/anime_human/ani_hu.h5')

"""--------------PREDICT--------------

"""

idx2 = random.randint(0, len(x_test))
plt.imshow(x_test[idx2,:])

y_pred = model.predict(x_test[idx2,:].reshape(1, 64, 64, 3))
print(y_pred)
if(y_pred > 0.5):
  print("Anime")
else:
  print("Human")

!pip install opencv-python pillow

import cv2
import numpy as np
import requests
import matplotlib.pyplot as plt
from PIL import Image
from io import BytesIO


image_url ="https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcTBDeqHMmyRrvywGRe_x6d-A-MUFHD-Z5k4J2RUKSSJapkrCgpX91p0omf7iKeLUruyarU&usqp=CAU"
try:

    response = requests.get(image_url, stream=True)
    response.raise_for_status()


    image = Image.open(BytesIO(response.content))


    plt.imshow(image)
    plt.axis("off")
    plt.show()


    target_size = (64, 64)


    image = np.array(image)


    if image.shape[-1] == 4:
        image = image[:, :, :3]


    image_resized = cv2.resize(image, target_size)


    image_resized = image_resized.astype("float32") / 255.0


    image_input = np.expand_dims(image_resized, axis=0)


    y_pred = model.predict(image_input)


    print("Raw prediction output:", y_pred)
    print("üëâ D·ª± ƒëo√°n:", "Anime" if y_pred > 0.5 else "Human")

except requests.exceptions.RequestException as e:
    print(f"‚ö†Ô∏è L·ªói khi t·∫£i ·∫£nh: {e}")